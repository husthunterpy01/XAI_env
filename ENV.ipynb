{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPc/mQ+19EXFzrufzO/GC6z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jeOP5_g8GKOK"},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"id":"Q9OFDLIpGMTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import h5py\n","import pickle\n","import torch\n","import time\n","import yaml\n","import copy\n","import math\n","import traceback\n","import sys\n","import time\n","import os\n","import torch.nn.functional as F\n","import torchvision\n","import transformers\n","from torch import optim\n","from torch.utils.data import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","from copy import deepcopy"],"metadata":{"id":"JYAtixp8GMWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yaml\n","with open('/home/quanhhh/Documents/RUL_XAI/XAI_env/config.yml', 'r') as f:\n","    config_wdb = yaml.safe_load(f)"],"metadata":{"id":"9vCchBxaGMZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config_wdb"],"metadata":{"id":"s22TDSbxGMbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, config, x_path, y_path):\n","        super().__init__()\n","        self.config = config\n","        self.x_path = x_path\n","        self.y_path = y_path\n","        self.load_dataset()\n","\n","    def __len__(self):\n","        return self.data_.shape[0]\n","\n","    def __getitem__(self, idx):\n","        input_tensor = torch.from_numpy(self.data_[idx]).float()\n","        label_tensor = torch.from_numpy(np.array(self.labels[idx])).float()\n","        return {'input': input_tensor, 'labels': label_tensor}\n","    def load_dataset(self):\n","        x_data = {}\n","        y_data = {}\n","        x_path_ = os.path.join(self.config['data_dir'], self.x_path)\n","        y_path_ = os.path.join(self.config['data_dir'], self.y_path)\n","\n","        with h5py.File(x_path_, 'r') as x_file:\n","            x_data_key = list(x_file.keys())[0]\n","            x_data['data'] = np.array(x_file[x_data_key])\n","\n","        with h5py.File(y_path_, 'r') as y_file:\n","            y_data_key = list(y_file.keys())[0]\n","            y_data['label'] = np.array(y_file[y_data_key])\n","\n","        self.data_ = x_data['data']\n","        self.labels = y_data['label']\n","        self.config['data_shape'] = self.data_.shape[1:]\n","\n","    def getshape(self):\n","        return self.config['data_shape']\n"],"metadata":{"id":"lDAGstChGMeX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Autoencoder(nn.Module):\n","    def __init__(self, input_size,embed_dim, noise_level):\n","        super(Autoencoder, self).__init__()\n","        self.embed_dim = embed_dim\n","        self.input_size, self.hidden_dim, self.noise_level = input_size, embed_dim,noise_level\n","        self.fc1 = nn.Linear(self.input_size, self.hidden_dim)\n","        self.fc2 = nn.Linear(self.hidden_dim, self.input_size)\n","\n","    def encoder(self,x):\n","        x = self.fc1(x)\n","        h1 = F.relu(x)\n","        return h1\n","\n","    def mask(self,x):\n","        corrupted_x = x + self.noise_level + torch.randn_like(x)   # randn_like  Initializes a tensor where all the elements are sampled from a normal distribution.\n","        return corrupted_x\n","\n","    def decoder(self, x):\n","        h2 = self.fc2(x)\n","        return h2\n","\n","    def forward (self, x):\n","        out = self.mask(x) # Adding noise to feed the network\n","        encoder = self.encoder(out)\n","        decoder = self.decoder(encoder)\n","        return decoder\n","    ## Transformer\n","    ### Positional encoding\n","class TransformerAE(nn.Module):\n","        def __init__(self, input_sizet,noise_level,embed_dim, hidden_size, num_layers, num_heads, dropout):\n","            super(TransformerAE, self).__init__()\n","\n","            self.embedding = nn.Linear(input_sizet, hidden_size)\n","            self.transformer = nn.Transformer(\n","                d_model=hidden_size,\n","                nhead=num_heads,\n","                num_encoder_layers=num_layers,\n","                num_decoder_layers=num_layers,\n","                dim_feedforward=hidden_size,\n","                dropout=dropout\n","            )\n","            self.fc = nn.Linear(hidden_size, input_sizet)\n","            self.autoencoder = Autoencoder(input_size = input_sizet, noise_level = noise_level, embed_dim = embed_dim)\n","\n","        def forward(self, input_sizet):\n","            decoder = self.autoencoder(input_sizet)\n","            embedded = self.embedding(decoder)\n","            embedded = embedded.permute(1, 0, 2)  # [sequence_len, batch_size, hidden_size]\n","            encoded = self.transformer(embedded, embedded)  # Self-attention n the input sequence\n","            encoded = encoded.permute(1, 0, 2)  # [batch_size, sequence_len, hidden_size]\n","            decoded = self.fc(encoded)\n","            return decoded\n"],"metadata":{"id":"pU8VM4MpGMhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Trainer\n","class ModelTrainer():\n","    def __init__(self, model, train_data, criterion, optimizer, device, config):\n","        self.model = model\n","        self.train_data = train_data\n","        self.device = device\n","        self.config = config\n","        self.train_loss_list = list()\n","        self.min_loss = float('inf')\n","        self.best_model = None\n","        self.best_optimizer = None\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","\n","    def train_epoch(self, epoch):\n","        train_loss = 0.0\n","        self.model.train()\n","        for i, batch in enumerate(self.train_data):\n","            x = batch[\"input\"].to(device)\n","            rul = batch[\"labels\"].to(device)\n","            rul = torch.reshape(rul[:, 1], (-1, 1))\n","            x = x.unsqueeze(1)\n","            out = self.model(x)\n","            loss = self.criterion(out,rul)\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            train_loss += loss\n","\n","\n","        train_loss = train_loss / len(self.train_data)\n","        wandb.log({\"train loss\": train_loss})\n","        self.train_loss_list.append(train_loss)\n","\n","        if train_loss < self.min_loss:\n","            self.min_loss = train_loss\n","            self.best_model = deepcopy(self.model.state_dict())\n","            self.best_optimizer = deepcopy(self.optimizer.state_dict())\n","            self.best_epoch_in_round = epoch\n","    # Set up the epoch for trainning process\n","    def train(self):\n","        try:\n","\n","            self.model.to(self.device)\n","\n","            for epoch in range(1, 100):\n","                self.train_epoch(epoch)\n","                wandb.log({\"epoch\": epoch})\n","\n","                self.config['train_loss_list'] = self.train_loss_list\n","        except Exception:\n","            traceback.print_exc()\n","\n","    def update_config(self):\n","        return self.config\n","\n","\n"],"metadata":{"id":"B--akKyDGMj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sweep_id = wandb.sweep(sweep=config_wdb, project='RUL_Bearing')"],"metadata":{"id":"g_NyfYD8GMmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train\n","torch.manual_seed(42)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def training():\n","    with wandb.init(config = config_wdb):\n","        config = wandb.config\n","        train_data = CustomDataset(config, '/home/quanhhh/Documents/RUL_XAI/XAI_env/data_processed/IMS/x_train.hdf5','/home/quanhhh/Documents/RUL_XAI/XAI_env/data_processed/IMS/y_train.hdf5')\n","        train_loader = DataLoader(train_data,\n","                                  batch_size=128,\n","                                  shuffle=True)\n","        shape = train_data.getshape()\n","        model = TransformerAE(input_sizet = shape[0],\n","            noise_level = 0.01,\n","            embed_dim = 16,\n","            hidden_size = 64,\n","            num_layers = 2,\n","            num_heads = 4,\n","            dropout = 0.1)\n","\n","        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config['weight_decay'])\n","        criterion = nn.MSELoss()\n","        trainer = ModelTrainer(model = model,\n","                               train_data = train_loader,\n","                               criterion = criterion ,\n","                               optimizer = optimizer,\n","                               device = device,\n","                               config = config)\n","        trainer.train()\n","\n","        test_data = CustomDataset(config,'/home/quanhhh/Documents/RUL_XAI/XAI_env/data_processed/IMS/x_test.hdf5','/home/quanhhh/Documents/RUL_XAI/XAI_env/data_processed/IMS/y_test.hdf5')\n","        test_loader = DataLoader(test_data,\n","                                  batch_size=128,\n","                                  shuffle=True)\n","        model.to(device)\n","        test_loss = 0.0\n","        test_loss_list = list()\n","        pred_list = list()\n","        truth_list = list()\n","        with torch.no_grad():\n","            for i, batch in enumerate(test_loader):\n","                x = batch[\"input\"].to(device)\n","                rul = batch[\"labels\"].to(device)\n","                rul = torch.reshape(rul[:, 1], (-1, 1))\n","                x = x.unsqueeze(1)\n","                out = model(x)\n","                loss = criterion(out,rul)\n","                test_loss += loss\n","                test_loss_list.append(loss)\n","                pred_list.append(out)\n","\n","        test_loss_avg = test_loss / len(test_loader)\n","\n","        for x, rul in enumerate(test_loader):\n","          rul = rul[\"labels\"]\n","          tensor_values = [value.item() for value in rul.flatten()]\n","          truth_list.extend(tensor_values)\n","\n","        #truth_list = [rul[\"labels\"][0].item() for x, rul in enumerate(test_loader)] #####\n","        #truth_list = [rul.item() for batch in test_loader for rul in batch[\"labels\"]]\n","        config['truth_list'] = truth_list\n","        config['pred_list'] = pred_list\n","        config['test_loss_avg'] = test_loss_avg\n","        config['test_loss_list_per_id'] = test_loss_list\n","        wandb.log({\"test_loss_avg\": test_loss_avg})\n","\n","        val_data = CustomDataset(config,'/home/quanhhh/Documents/RUL_XAI/XAI_env/data_processed/IMS/x_val.hdf5','/home/quanhhh/Documents/RUL_XAI/XAI_env/data_processed/IMS/y_val.hdf5' )\n","        val_loader = DataLoader(val_data,\n","                                 batch_size=128,\n","                                 shuffle=True)\n","        model.to(device)\n","        val_loss = 0.0\n","        val_loss_list = list()\n","        with torch.no_grad():\n","            for i, batch in enumerate(val_loader):\n","                x = batch[\"input\"].to(device)\n","                rul = batch[\"labels\"].to(device)\n","                rul = torch.reshape(rul[:, 1], (-1, 1))\n","                x = x.unsqueeze(1)\n","                out = model(x)\n","                loss = criterion(out,rul)\n","                val_loss += loss\n","                val_loss_list.append(loss)\n","        val_loss_avg = val_loss / len(test_loader)\n","        config['val_loss_avg'] = test_loss_avg\n","        config['val_loss_list_per_id'] = test_loss_list\n","        wandb.log({\"val_loss_avg\": test_loss_avg})\n",""],"metadata":{"id":"-VA34dZBGjhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!date\n","wandb.agent(sweep_id, function=training ,count = 200)"],"metadata":{"id":"HckeIoGDGMpK"},"execution_count":null,"outputs":[]}]}
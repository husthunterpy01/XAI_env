{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3ca05fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4fce8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import h5py\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import yaml\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bb78549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_wbd = {}\n",
    "with open('/home/quang/Documents/XAI_env-main/Code/config.yml', 'r') as f:\n",
    "    config_wdb = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe07d117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'bayes',\n",
       " 'metric': {'goal': 'minimize', 'name': 'test_loss_avg'},\n",
       " 'parameters': {'batch_size': {'values': [128]},\n",
       "  'd_model': {'value': 16},\n",
       "  'dff': {'values': [128, 256]},\n",
       "  'dropout': {'distribution': 'uniform', 'min': 0.05, 'max': 0.15},\n",
       "  'l_win': {'distribution': 'int_uniform', 'min': 120, 'max': 125},\n",
       "  'lr': {'distribution': 'log_uniform', 'min': -6.5, 'max': -5.5},\n",
       "  'n_epochs': {'distribution': 'int_uniform', 'min': 60, 'max': 100},\n",
       "  'n_head': {'values': [1, 23]},\n",
       "  'num_layers': {'distribution': 'int_uniform', 'min': 1, 'max': 3},\n",
       "  'weight_decay': {'distribution': 'log_uniform', 'min': -6, 'max': -4},\n",
       "  'noise_level': {'min': 0.01, 'max': 0.05},\n",
       "  'embed_dim': 8}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_wdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d1f5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "# Noisy Data loader\n",
    "# Assume that we will take the preprocessing process by the original paper\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,config,x_path,y_path):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.x_path = x_path\n",
    "        self.y_path = y_path\n",
    "        self.load_dataset()\n",
    "    # Return the length of the data\n",
    "    def __len__(self):\n",
    "        return self.data_.shape[0]\n",
    "    # Defining the dataframe and label for the data before entering the model\n",
    "    def __getitem__(self,idx):\n",
    "        return {'input':self.data_[index], \n",
    "                'labels': self.labels[index]}\n",
    "\n",
    "     # The following will be used in order to prepare to use the data_loader to put the dataset into the model\n",
    "    def load_dataset(self,dataset):\n",
    "        x_data = {}\n",
    "        y_data = {}\n",
    "        x_path_ = self.config['data_dir'] + self.x_path\n",
    "        y_path_ = self.config['data_dir'] + self.y_path\n",
    "        \n",
    "        with h5py.File(x_path_, 'rb') as x_file:\n",
    "            x_data['data'] = np.array(x_file['data'])\n",
    "        \n",
    "        with h5py.File(y_path_, 'rb') as y_file:\n",
    "            y_data['label'] = np.array(y_file['label'])\n",
    "\n",
    "        self.data_ = x_data['data'].transpose(0, 2, 1)\n",
    "        self.data_ = np.expand_dims(self.data_, axis=1)\n",
    "        \n",
    "        self.labels = y_data['label']\n",
    "    #Return the shape of the data_ everytime passing by\n",
    "    def getshape(self):\n",
    "        return self.data_.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7027c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer \n",
    "class ModelTrainer():\n",
    "    def __init__(self, model, train_data, criterion, optimizer, device, config):\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.train_loss_list = list()\n",
    "        self.min_loss = float('inf')\n",
    "        self.best_model = None\n",
    "        self.best_optimizer = None\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        train_loss = 0.0\n",
    "        self.model.train()\n",
    "        for x, rul in self.train_data:\n",
    "            self.model.zero_grad()\n",
    "            out = self.model(x.to(self.device).float())\n",
    "            loss = torch.sqrt(self.criterion(out.float(), rul.to(self.device).float())) # RMSE\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss\n",
    "\n",
    "        train_loss = train_loss / len(self.train_data)\n",
    "        wandb.log({\"train loss\": train_loss})\n",
    "        self.train_loss_list.append(train_loss)\n",
    "\n",
    "        if train_loss < self.min_loss:\n",
    "            self.min_loss = train_loss\n",
    "            self.best_model = deepcopy(self.model.state_dict())\n",
    "            self.best_optimizer = deepcopy(self.optimizer.state_dict())\n",
    "            self.best_epoch_in_round = epoch\n",
    "    # Set up the epoch for trainning process\n",
    "    def train(self):\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        for epoch in range(1, self.config['n_epochs'] + 1):\n",
    "            self.train_epoch(epoch)\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "\n",
    "        self.config['train_loss_list'] = self.train_loss_list\n",
    "\n",
    "    def update_config(self):\n",
    "        return self.config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a60d0545",
   "metadata": {},
   "outputs": [
    {
     "ename": "CommError",
     "evalue": "argument of type 'int' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_api.py:2473\u001b[0m, in \u001b[0;36mApi.upsert_sweep\u001b[0;34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state)\u001b[0m\n\u001b[1;32m   2471\u001b[0m mutations \u001b[38;5;241m=\u001b[39m [mutation_4, mutation_3, mutation_2, mutation_1]\n\u001b[0;32m-> 2473\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_config_and_fill_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;66;03m# Silly, but attr-dicts like EasyDicts don't serialize correctly to yaml.\u001b[39;00m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;66;03m# This sanitizes them with a round trip pass through json to get a regular dict.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_api.py:2360\u001b[0m, in \u001b[0;36mApi._validate_config_and_fill_distribution\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m   2359\u001b[0m parameter \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m][parameter_name]\n\u001b[0;32m-> 2360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameter\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parameter:\n\u001b[1;32m   2361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parameter:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sweep_id \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_wdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRUL_Bearing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_sweep.py:110\u001b[0m, in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    108\u001b[0m     wandb_login\u001b[38;5;241m.\u001b[39m_login(_silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    109\u001b[0m api \u001b[38;5;241m=\u001b[39m InternalApi()\n\u001b[0;32m--> 110\u001b[0m sweep_id, warnings \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m handle_sweep_config_violations(warnings)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate sweep with ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sweep_id)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/internal.py:126\u001b[0m, in \u001b[0;36mApi.upsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert_sweep\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/normalize.py:87\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err)\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/apis/normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhoa, you found a bug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     43\u001b[0m     errors \u001b[38;5;241m=\u001b[39m parse_backend_error_messages(error\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_api.py:2473\u001b[0m, in \u001b[0;36mApi.upsert_sweep\u001b[0;34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state)\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[38;5;66;03m# TODO(dag): replace this with a query for protocol versioning\u001b[39;00m\n\u001b[1;32m   2471\u001b[0m mutations \u001b[38;5;241m=\u001b[39m [mutation_4, mutation_3, mutation_2, mutation_1]\n\u001b[0;32m-> 2473\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_config_and_fill_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;66;03m# Silly, but attr-dicts like EasyDicts don't serialize correctly to yaml.\u001b[39;00m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;66;03m# This sanitizes them with a round trip pass through json to get a regular dict.\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m config_str \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mdump(json\u001b[38;5;241m.\u001b[39mloads(json\u001b[38;5;241m.\u001b[39mdumps(config)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/internal/internal_api.py:2360\u001b[0m, in \u001b[0;36mApi._validate_config_and_fill_distribution\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parameter_name \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   2359\u001b[0m     parameter \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m][parameter_name]\n\u001b[0;32m-> 2360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameter\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parameter:\n\u001b[1;32m   2361\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parameter:\n\u001b[1;32m   2362\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   2363\u001b[0m                 parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m   2364\u001b[0m             ):\n",
      "\u001b[0;31mCommError\u001b[0m: argument of type 'int' is not iterable"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep=config_wdb, project='RUL_Bearing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e39b8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "torch.manual_seed(42)\n",
    "def training():\n",
    "    with wandb.init(config = config_wbd):\n",
    "        config - wandb.config\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        train_data = CustomDataset(config, '/home/quang/Documents/XAI_env-main/data/processed/IMS/x_train.hdf5','/home/quang/Documents/XAI_env-main/data/processed/IMS/y_train.hdf5')\n",
    "        train_loader = DataLoader(train_data,\n",
    "                                  batch_size=128,\n",
    "                                  shuffle=True)\n",
    "        shape = train_data.getshape()\n",
    "        model = Net(d_model=config['d_model'],\n",
    "                    nhead=config['n_head'],\n",
    "                    feature_size = shape,\n",
    "                    noise_level = config['noise_level'],\n",
    "                    embed_dim = config['embed_dim'],\n",
    "                    n_head = configp['n_head'],\n",
    "                    num_layers=config['num_layers'],\n",
    "                    dropout=config['dropout'],\n",
    "                    l_win=config['l_win'])\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config['weight_decay'])\n",
    "        criterion = nn.MSELoss()\n",
    "        trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, config)\n",
    "        trainer.train()\n",
    "\n",
    "        test_data = CustomDataset(config,'/home/quang/Documents/XAI_env-main/data/processed/IMS/x_test.hdf5','/home/quang/Documents/XAI_env-main/data/processed/IMS/y_test.hdf5')\n",
    "        test_loader = DataLoader(test_data,\n",
    "                                  batch_size=128,\n",
    "                                  shuffle=True)\n",
    "        model.to(device)\n",
    "        test_loss = 0.0\n",
    "        test_loss_list = list()\n",
    "        pred_list = list()\n",
    "        with torch.no_grad():\n",
    "            for x, rul in test_loader:\n",
    "                out = model(x.to(device).float())\n",
    "                loss = torch.sqrt(criterion(out.float(), rul.to(device).float()))\n",
    "                test_loss += loss\n",
    "                test_loss_list.append(loss)\n",
    "                pred_list.append(out.float())\n",
    "\n",
    "        test_loss_avg = test_loss / len(test_loader)\n",
    "        config['truth_list'] = truth_list\n",
    "        config['pred_list'] = pred_list\n",
    "        config['test_loss_avg'] = test_loss_avg\n",
    "        config['test_loss_list_per_id'] = test_loss_list\n",
    "        wandb.log({\"test_loss_avg\": test_loss_avg})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        vak_data = CustomDataset(config,'/home/quang/Documents/XAI_env-main/data/processed/IMS/x_val.hdf5','/home/quang/Documents/XAI_env-main/data/processed/IMS/y_val.hdf5' )\n",
    "        val_loader = DataLoader(val_data,\n",
    "                                 batch_size=128,\n",
    "                                 shuffle=True)\n",
    "        model.to(device)\n",
    "        val_loss = 0.0\n",
    "        val_loss_list = list()\n",
    "        with torch.no_grad():\n",
    "            for x, rul in val_loader:\n",
    "                out = model(x.to(device).float())\n",
    "                loss = torch.sqrt(criterion(out.float(), rul.to(device).float()))\n",
    "                val_loss += loss\n",
    "                val_loss_list.append(loss)\n",
    "        val_loss_avg = val_loss / len(test_loader)\n",
    "        config['val_loss_avg'] = test_loss_avg\n",
    "        config['val_loss_list_per_id'] = test_loss_list\n",
    "        wandb.log({\"val_loss_avg\": test_loss_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "664f6adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thứ tư, 31 Tháng 5 năm 2023 14:03:27 +07\r\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sweep_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m wandb\u001b[38;5;241m.\u001b[39magent(\u001b[43msweep_id\u001b[49m, function\u001b[38;5;241m=\u001b[39mtrainning ,count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sweep_id' is not defined"
     ]
    }
   ],
   "source": [
    "!date\n",
    "wandb.agent(sweep_id, function=trainning ,count = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89189da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
